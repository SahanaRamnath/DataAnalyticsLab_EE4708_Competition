{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "import scipy.misc\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read dataset1\n",
    "full_face = []\n",
    "full_labels = []\n",
    "all_images = os.listdir('yalefaces')\n",
    "for j in range(1,16):    # there are 15 different people in the dataset\n",
    "    img_list = [filename for filename in all_images if filename.startswith('subject%.2d'%j)]\n",
    "#     img_list = glob.glob('yalefaces/subject%.2d*'%j)\n",
    "    face1 = np.zeros((len(img_list),32,32))\n",
    "    for k,img in enumerate(img_list):\n",
    "        I = scipy.misc.imread(os.path.join('yalefaces',img))\n",
    "        I = cv2.fastNlMeansDenoising(I, None, 9, 13)\n",
    "        I = cv2.GaussianBlur(I, (5,5), 0)\n",
    "        I = cv2.equalizeHist(I)\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            I,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30))\n",
    "        try : \n",
    "            x,y,h,w = faces[0]\n",
    "            face1[k,...] = zoom(I[y:y+h,x:x+w],[32./h,32./w])     \n",
    "        except : \n",
    "            x,y,h,w=[0,0,479,639]\n",
    "            face1[k,...] = zoom(I[y:y+h,x:x+w],[32./h,32./w])   \n",
    "        \n",
    "    labels = (j-1)*np.ones((11,))\n",
    "    full_face.append(face1)\n",
    "    full_labels.append(labels)\n",
    "full_face = np.stack(full_face)    # contains the images of all faces\n",
    "full_labels = np.stack(full_labels)   # contains the ID of all the faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_face = full_face/255 #normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 11, 32, 32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_face.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 11)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar 1 dissimilar 0\n",
    "# 2 images of the same person\n",
    "pairs = []\n",
    "labels = []\n",
    "similarity = []\n",
    "for i in range(0,15):\n",
    "    for j in range(50):\n",
    "        a = np.random.randint(0,11,2)\n",
    "        labels.append([i,i])\n",
    "        pairs.append(a)\n",
    "        similarity.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar 1 dissimilar 0\n",
    "# 2 images of same and different people\n",
    "similarity=[]\n",
    "labels = []\n",
    "similarity = []\n",
    "sim=0\n",
    "nonsim=0\n",
    "for i in range(0,10000):\n",
    "        b = np.random.randint(0,15,2)\n",
    "        a = np.random.randint(0,11,2)\n",
    "        \n",
    "        \n",
    "        if(b[0]==b[1]):\n",
    "            similarity.append(1)\n",
    "            labels.append(b)\n",
    "            pairs.append(a)\n",
    "            sim+=1\n",
    "        else:\n",
    "            if nonsim>sim : \n",
    "                continue\n",
    "            else : \n",
    "                similarity.append(0)\n",
    "                labels.append(b)\n",
    "                pairs.append(a)\n",
    "                nonsim+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1339 669\n"
     ]
    }
   ],
   "source": [
    "print(len(similarity),sum(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.zeros((len(similarity),32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "face1 = full_face[a[0],b[0],:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity,euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(similarity),32*32))\n",
    "for i in range(len(similarity)):\n",
    "    a = labels[i]\n",
    "    b = pairs[i]\n",
    "    face1 = full_face[a[0],b[0],:,:]\n",
    "    face2 = full_face[a[1],b[1],:,:]\n",
    "    face = face1-face2\n",
    "    face = euclidean_distances(face,face)\n",
    "    trainX[i,:,:]=face\n",
    "    X_train[i,:]=trainX[i,:,:].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1339, 1024)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain1,xtest1,ytrain,ytest=train_test_split(X_train, similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1004, 1024)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "# if PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(whiten=True)\n",
    "pca.fit(xtrain1)\n",
    "n_components = np.argmin(np.cumsum(pca.explained_variance_ratio_)<=0.99)\n",
    "print(n_components)\n",
    "xtrain=pca.transform(xtrain1)\n",
    "xtrain=xtrain[:,:n_components]\n",
    "xtest=pca.transform(xtest1)\n",
    "xtest=xtest[:,:n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2437, 1) (813, 1)\n"
     ]
    }
   ],
   "source": [
    "# if LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda=LinearDiscriminantAnalysis()\n",
    "lda.fit(xtrain1,ytrain)\n",
    "xtrain=lda.transform(xtrain1)\n",
    "xtest=lda.transform(xtest1)\n",
    "print(xtrain.shape,xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if nothing\n",
    "xtrain=xtrain1\n",
    "xtest=xtest1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 5), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5,5), random_state=1)\n",
    "#clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(1), random_state=1)\n",
    "clf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.9721115537848606\n",
      "Test Accuracy :  0.8805970149253731\n",
      "Train F1 Score :  0.9714867617107942\n",
      "Test F1 Score :  0.8863636363636365\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.9684037751333607\n",
      "Test Accuracy :  0.9212792127921279\n",
      "Train F1 Score :  0.9446441409058232\n",
      "Test F1 Score :  0.8565022421524664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression(C=50)\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.8884462151394422\n",
      "Test Accuracy :  0.8\n",
      "Train F1 Score :  0.8808510638297872\n",
      "Test F1 Score :  0.8023598820058997\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=4,random_state=0)\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.9342629482071713\n",
      "Test Accuracy :  0.8208955223880597\n",
      "Train F1 Score :  0.9313929313929313\n",
      "Test F1 Score :  0.8245614035087718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf=DecisionTreeClassifier(criterion='entropy',max_depth=7)#,max_features='sqrt')\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "h5f = h5py.File('test.h5','r')\n",
    "a = list(h5f.keys())\n",
    "## read the dataset\n",
    "full_face = []\n",
    "full_labels = []\n",
    "img_list=[h5f[i] for i in a]\n",
    "tface1 = np.zeros((len(img_list),32,32))\n",
    "for k,img in enumerate(img_list):\n",
    "    I = np.array(img)#scipy.misc.imread(os.path.join('yalefaces',img))\n",
    "    #print(type(I))\n",
    "    I = cv2.fastNlMeansDenoising(I, None, 9, 13)\n",
    "    I = cv2.GaussianBlur(I, (5,5), 0)\n",
    "    I = cv2.equalizeHist(I)\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        I,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30))\n",
    "    #print(k)\n",
    "    #print(faces)\n",
    "    try : \n",
    "        x,y,h,w = faces[0]\n",
    "        tface1[k,...] = zoom(I[y:y+h,x:x+w],[32./h,32./w])\n",
    "    except : \n",
    "        x,y,h,w=[0,0,111,91]\n",
    "        tface1[k,...] = zoom(I[y:y+h,x:x+w],[32./h,32./w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 32, 32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tface1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "tface1 = tface1/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs = np.genfromtxt('image_pairs.csv', dtype=None, delimiter=',', names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n"
     ]
    }
   ],
   "source": [
    "euc=[]\n",
    "\n",
    "for i in range(3540):#(3540):\n",
    "    x1 = np.zeros((32,32))\n",
    "    x0 = np.zeros((32,32))\n",
    "    ids = test_pairs[i][0]\n",
    "    image1=test_pairs[i][1]\n",
    "    image2=test_pairs[i][2]\n",
    "    x0 = tface1[a.index(str(test_pairs[i][1])),:,:]\n",
    "    x1 = tface1[a.index(str(test_pairs[i][2])),:,:]\n",
    "    if(i%100==0):\n",
    "        print(i)\n",
    "    face = x0-x1\n",
    "    face = euclidean_distances(face,face)\n",
    "    face=face.ravel()\n",
    "    inp = np.zeros((1,32*32))\n",
    "    inp[0,:]=face\n",
    "    #inp=pca.transform(inp)\n",
    "    #inp=inp[:,:n_components]\n",
    "    euc.append(clf.predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 is similar; 0 is different\n",
    "with open('dt2.csv','w') as f : \n",
    "    f.write('Id,Expected\\n')\n",
    "    for i in range(len(test_pairs)) : \n",
    "        ids = test_pairs[i][0]\n",
    "        temp = euc[i][0]\n",
    "        f.write(str(ids)+','+str(temp)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "euc = np.asarray(euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([216])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
