{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "import scipy.misc\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},

   "outputs": [],
   "source": [
    "from skimage.feature import hog#Terrible results; Train and test F1 score of 0 with this. \n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## read dataset1\n",
    "full_face = []\n",
    "full_labels = []\n",
    "all_images = os.listdir('yalefaces')\n",
    "for j in range(1,16):    # there are 15 different people in the dataset\n",
    "    img_list = [filename for filename in all_images if filename.startswith('subject%.2d'%j)]\n",
    "#     img_list = glob.glob('yalefaces/subject%.2d*'%j)\n",
    "    img_list=img_list[0:10]#Get only 10 faces of each category\n",
    "    face1 = np.zeros((len(img_list),64,64))\n",
    "    for k,img in enumerate(img_list):\n",
    "        I = scipy.misc.imread(os.path.join('yalefaces',img))\n",
    "        I = cv2.fastNlMeansDenoising(I, None, 9, 13)\n",
    "        I = cv2.GaussianBlur(I, (5,5), 0)\n",
    "        I = cv2.equalizeHist(I)\n",
    "\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            I,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30))\n",
    "        #fd, hog_image = hog(I, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualise=True)\n",
    "        #I = hog_image\n",
    "        I = local_binary_pattern(I,8,3)\n",
    "        try : \n",
    "            x,y,h,w = faces[0]\n",
    "            face1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])     \n",
    "        except : \n",
    "            x,y,h,w=[0,0,479,639]\n",
    "            face1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])\n",
    "            \n",
    "        \n",
    "    labels = (j-1)*np.ones((10,))\n",
    "    full_face.append(face1)\n",
    "    full_labels.append(labels)\n",
    "#full_face = np.stack(full_face)    # contains the images of all faces\n",
    "#full_labels = np.stack(full_labels)   # contains the ID of all the faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_face = full_face/255 #normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 11, 32, 32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(0,15):\\n    for j in range(50):\\n        a = np.random.randint(0,11,2)\\n        labels.append([i,i])\\n        pairs.append(a)\\n        similarity.append(1)\\n'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similar 1 dissimilar 0\n",
    "pairs = []\n",
    "labels = []\n",
    "similarity = []\n",
    "'''\n",
    "for i in range(0,15):\n",
    "    for j in range(50):\n",
    "        a = np.random.randint(0,11,2)\n",
    "        labels.append([i,i])\n",
    "        pairs.append(a)\n",
    "        similarity.append(1)\n",
    "'''       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(0,750):\\n        b = np.random.randint(0,15,2)\\n        a = np.random.randint(0,11,2)\\n        labels.append(b)\\n        pairs.append(a)\\n        if(b[0]==b[1]):\\n            similarity.append(1)\\n        else:\\n            similarity.append(0)\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similar 1 dissimilar 0\n",
    "# 2 images of same and different people\n",
    "similarity=[]\n",
    "labels = []\n",
    "pairs = []\n",
    "sim=0\n",
    "nonsim=0\n",
    "for i in range(0,20000):\n",
    "        b = np.random.randint(0,15,2)\n",
    "        a = np.random.randint(0,11,2)\n",
    "        labels.append(b)\n",
    "        pairs.append(a)\n",
    "        if(b[0]==b[1]):\n",
    "            similarity.append(1)\n",
    "        else:\n",
    "            similarity.append(0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2583 1291\n"
     ]
    }
   ],
   "source": [
    "#More data from att_faces\n",
    "for j in range(16,40):    # there are 40 different people in the dataset\n",
    "    img_list = []\n",
    "    for i in range(1,11):\n",
    "        img_list.append('att_faces/s'+str(j)+'/'+str(i)+'.pgm')\n",
    "#     img_list = glob.glob('yalefaces/subject%.2d*'%j)\n",
    "    face1 = np.zeros((len(img_list),64,64))\n",
    "    for k,img in enumerate(img_list):\n",
    "        I = scipy.misc.imread(img)\n",
    "        I = cv2.fastNlMeansDenoising(I, None, 9, 13)\n",
    "        I = cv2.GaussianBlur(I, (5,5), 0)\n",
    "        I = cv2.equalizeHist(I)\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            I,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30))\n",
    "        #fd, hog_image = hog(I, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualise=True)\n",
    "        #I = hog_image\n",
    "        I = local_binary_pattern(I,8,3)\n",
    "        try : \n",
    "            x,y,h,w = faces[0]\n",
    "            face1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])     \n",
    "        except : \n",
    "            x,y,h,w=[0,0,112,92]\n",
    "            face1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])   \n",
    "        \n",
    "    labels = (j-1)*np.ones((10,))\n",
    "    full_face.append(face1)\n",
    "    full_labels.append(labels)\n",
    "full_face = np.stack(full_face)    # contains the images of all faces\n",
    "full_labels = np.stack(full_labels)   # contains the ID of all the faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_face = full_face/255 #normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_face[10])"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 171,
   "metadata": {},

   "outputs": [],
   "source": [
    "#similar 1 dissimilar 0\n",
    "pairs = []\n",
    "labels = []\n",
    "similarity = []\n",
    "for i in range(0,39):\n",
    "    for j in range(40):\n",
    "        a = np.random.randint(0,10,2)\n",
    "        labels.append([i,i])\n",
    "        pairs.append(a)\n",
    "        similarity.append(1)\n",
    "#similar 1 dissimilar 0\n",
    "for i in range(0,2000):\n",
    "        b = np.random.randint(0,39,2)\n",
    "        a = np.random.randint(0,10,2)\n",
    "        labels.append(b)\n",
    "        pairs.append(a)\n",
    "        if(b[0]==b[1]):\n",
    "            similarity.append(1)\n",
    "        else:\n",
    "            similarity.append(0)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(similarity),64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.zeros((len(similarity),64*64))\n",
    "for i in range(len(similarity)):\n",
    "    a = labels[i]\n",
    "    b = pairs[i]\n",
    "    face1 = full_face[a[0],b[0],:,:]\n",
    "    face2 = full_face[a[1],b[1],:,:]\n",
    "    #face = face1-face2\n",
    "    #face = abs(np.multiply(face1,face1)-np.multiply(face2,face2))#cosine_similarity(face1,face2)\n",
    "    #trainX[i,:,:]=face\n",
    "    #X_train[i,:]=trainX[i,:,:].ravel()"
    "    face = face1-face2\n",
    "    face = np.multiply(face,face)\n",
    "    face = np.cos(face)\n",
    "    #face = cosine_similarity(face1,face2)\n",
    "    X[i,:,:]=face\n",
    "    X1[i,:]=X[i,:,:].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.69142637e-01, 7.57862361e-02, 0.00000000e+00, ...,\n",
       "        4.92118416e-03, 4.03998462e-02, 3.63321799e-01],\n",
       "       [4.95301807e-01, 9.59630911e-03, 3.07574010e-04, ...,\n",
       "        5.12110727e-03, 5.92079969e-03, 1.04575163e-01],\n",
       "       [8.87043445e-02, 0.00000000e+00, 4.61361015e-05, ...,\n",
       "        4.30603614e-03, 6.88965782e-03, 7.39715494e-03],\n",
       "       ...,\n",
       "       [7.19723183e-01, 7.15555556e-01, 7.07128028e-01, ...,\n",
       "        3.53710111e-02, 2.08535179e-02, 1.37793156e-02],\n",
       "       [7.85866974e-01, 7.32041522e-01, 8.30449827e-01, ...,\n",
       "        1.46405229e-02, 4.05997693e-02, 7.75086505e-02],\n",
       "       [6.98577470e-01, 7.32041522e-01, 8.27204921e-01, ...,\n",
       "        3.55247982e-03, 4.34755863e-02, 1.22260669e-02]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2583, 1024)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain1,xtest1,ytrain,ytest=train_test_split(X_train, similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1937, 1024)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain1.shape"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#Better results without PCA; so don't use this\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(whiten=True)\n",
    "pca.fit(xtrain1)\n",
    "n_components = np.argmin(np.cumsum(pca.explained_variance_ratio_)<=0.8)\n",
    "print(n_components)\n",
    "xtrain=pca.transform(xtrain)\n",
    "xtrain=xtrain[:,:n_components]\n",
    "xtest=pca.transform(xtest)\n",
    "xtest=xtest[:,:n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

      "Train Accuracy :  0.5537219101123596\n",
      "Test Accuracy :  0.5126404494382022\n",
      "Train F1 Score :  0.0\n",
      "Test F1 Score :  0.0\n"
     ]
    }
   ],
   "source": [
    "# if LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda=LinearDiscriminantAnalysis()\n",
    "lda.fit(xtrain1,ytrain)\n",
    "xtrain=lda.transform(xtrain1)\n",
    "xtest=lda.transform(xtest1)\n",
    "print(xtrain.shape,xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if nothing\n",
    "xtrain=xtrain1\n",
    "xtest=xtest1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 5), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(2,5), random_state=1)\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.8918539325842697\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.8946648426812586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression(C=1000)\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9508426966292135\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.9476831091180867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=400, max_depth=16,random_state=0)#200 estimators gives good results\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9691011235955056\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.9673590504451038\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#clf = RandomForestClassifier(n_estimators=15, max_depth=15,random_state=7)\n",
    "clf = AdaBoostClassifier(n_estimators=400, base_estimator=RandomForestClassifier(max_depth=6))#200 n_estimators gives best results and took us to the third position on the leaderboard. \n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.6474719101123596\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.7349524815205914\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#clf=DecisionTreeClassifier(criterion='entropy',max_depth=12)#,max_features='sqrt')\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "clf = GaussianNB()\n",
    "clf = GaussianProcessClassifier()\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "h5f = h5py.File('test.h5','r')\n",
    "a = list(h5f.keys())\n",
    "## read the dataset\n",
    "full_face = []\n",
    "full_labels = []\n",
    "img_list=[h5f[i] for i in a]\n",
    "tface1 = np.zeros((len(img_list),64,64))\n",
    "for k,img in enumerate(img_list):\n",
    "    I = np.array(img)#scipy.misc.imread(os.path.join('yalefaces',img))\n",
    "    #print(type(I))\n",
    "    I = cv2.fastNlMeansDenoising(I, None, 9, 13)\n",
    "    I = cv2.GaussianBlur(I, (5,5), 0)\n",
    "    I = cv2.equalizeHist(I)\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        I,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30))\n",
    "    #print(k)\n",
    "    #print(faces)\n",
    "    #fd, hog_image = hog(I, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualise=True)\n",
    "    #I = hog_image\n",
    "    I = local_binary_pattern(I,8,3)\n",
    "    try : \n",
    "        x,y,h,w = faces[0]\n",
    "        tface1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])\n",
    "    except : \n",
    "        x,y,h,w=[0,0,111,91]\n",
    "        tface1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=1,\n",
      "            oob_score=False, random_state=7, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120, 64, 64)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clf)\n",
    "tface1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "tface1 = tface1/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs = np.genfromtxt('image_pairs.csv', dtype=None, delimiter=',', names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n"
     ]
    }
   ],
   "source": [
    "euc=[]\n",
    "\n",
    "for i in range(3540):#(3540):\n",
    "    x1 = np.zeros((64,64))\n",
    "    x0 = np.zeros((64,64))\n",
    "    ids = test_pairs[i][0]\n",
    "    image1=test_pairs[i][1]\n",
    "    image2=test_pairs[i][2]\n",
    "    x0 = tface1[a.index(str(test_pairs[i][1])),:,:]\n",
    "    x1 = tface1[a.index(str(test_pairs[i][2])),:,:]\n",
    "    if(i%100==0):\n",
    "        print(i)\n",
    "    face = x0-x1\n",
    "    face = np.multiply(face,face)\n",
    "    face = np.cos(face)\n",
    "    face=face.ravel()\n",
    "    inp = np.zeros((1,64*64))\n",
    "    inp[0,:]=face\n",
    "    inp=pca.transform(inp)\n",
    "    inp=inp[:,:n_components]\n",
    "    euc.append(clf.predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 is similar; 0 is different\n",
    "with open('to_submit/rf4.csv','w') as f : \n",

    "    f.write('Id,Expected\\n')\n",
    "    for i in range(len(test_pairs)) : \n",
    "        ids = test_pairs[i][0]\n",
    "        temp = euc[i][0]\n",
    "        f.write(str(ids)+','+str(temp)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "euc = np.asarray(euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1367"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([544])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
