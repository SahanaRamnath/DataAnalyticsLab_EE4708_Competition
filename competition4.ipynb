{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "import scipy.misc\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read dataset1\n",
    "full_face = []\n",
    "full_labels = []\n",
    "all_images = os.listdir('yalefaces')\n",
    "for j in range(1,16):    # there are 15 different people in the dataset\n",
    "    img_list = [filename for filename in all_images if filename.startswith('subject%.2d'%j)]\n",
    "#     img_list = glob.glob('yalefaces/subject%.2d*'%j)\n",
    "    face1 = np.zeros((len(img_list),64,64))\n",
    "    for k,img in enumerate(img_list):\n",
    "        I = scipy.misc.imread(os.path.join('yalefaces',img))\n",
    "        I = cv2.fastNlMeansDenoising(I, None, 9, 13)\n",
    "        I = cv2.GaussianBlur(I, (5,5), 0)\n",
    "        I = cv2.equalizeHist(I)\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            I,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30))\n",
    "        try : \n",
    "            x,y,h,w = faces[0]\n",
    "            face1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])     \n",
    "        except : \n",
    "            x,y,h,w=[0,0,479,639]\n",
    "            face1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])   \n",
    "        \n",
    "    labels = (j-1)*np.ones((11,))\n",
    "    full_face.append(face1)\n",
    "    full_labels.append(labels)\n",
    "full_face = np.stack(full_face)    # contains the images of all faces\n",
    "full_labels = np.stack(full_labels)   # contains the ID of all the faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 11, 64, 64)\n",
      "(15, 11)\n"
     ]
    }
   ],
   "source": [
    "full_face = full_face/255 #normalise data\n",
    "print(full_face.shape)\n",
    "print(full_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar 1 dissimilar 0\n",
    "# 2 images of same and different people\n",
    "similarity=[]\n",
    "labels = []\n",
    "pairs = []\n",
    "sim=0\n",
    "nonsim=0\n",
    "for i in range(0,40000):\n",
    "        b = np.random.randint(0,15,2)\n",
    "        a = np.random.randint(0,11,2)\n",
    "        \n",
    "        \n",
    "        if(b[0]==b[1]):\n",
    "            similarity.append(1)\n",
    "            labels.append(b)\n",
    "            pairs.append(a)\n",
    "            sim+=1\n",
    "        else:\n",
    "            if nonsim>sim : \n",
    "                continue\n",
    "            else : \n",
    "                similarity.append(0)\n",
    "                labels.append(b)\n",
    "                pairs.append(a)\n",
    "                nonsim+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5371 2685\n"
     ]
    }
   ],
   "source": [
    "print(len(similarity),sum(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.zeros((len(similarity),64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity,euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(similarity),64*64))\n",
    "for i in range(len(similarity)):\n",
    "    a = labels[i]\n",
    "    b = pairs[i]\n",
    "    face1 = full_face[a[0],b[0],:,:]\n",
    "    face2 = full_face[a[1],b[1],:,:]\n",
    "    face = face1-face2\n",
    "    face= euclidean_distances(face,face)#np.multiply(face,face)#abs(np.multiply(face1,face1)-np.multiply(face2,face2))\n",
    "    #face=cosine_similarity(face3,face3)\n",
    "    trainX[i,:,:]=face\n",
    "    X_train[i,:]=trainX[i,:,:].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.29382992, 0.5791189 , ..., 3.0169609 , 2.85484271,\n",
       "        2.95690695],\n",
       "       [0.29382992, 0.        , 0.32142512, ..., 2.9129284 , 2.75516362,\n",
       "        2.85586334],\n",
       "       [0.5791189 , 0.32142512, 0.        , ..., 2.85617565, 2.70936406,\n",
       "        2.8077199 ],\n",
       "       ...,\n",
       "       [3.0169609 , 2.9129284 , 2.85617565, ..., 0.        , 0.5631378 ,\n",
       "        0.54854321],\n",
       "       [2.85484271, 2.75516362, 2.70936406, ..., 0.5631378 , 0.        ,\n",
       "        0.26484383],\n",
       "       [2.95690695, 2.85586334, 2.8077199 , ..., 0.54854321, 0.26484383,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5371, 4096)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain1,xtest1,ytrain,ytest=train_test_split(X_train, similarity,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3684, 4096)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n"
     ]
    }
   ],
   "source": [
    "# if PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(whiten=True)\n",
    "pca.fit(xtrain1)\n",
    "n_components = np.argmin(np.cumsum(pca.explained_variance_ratio_)<=0.99)\n",
    "print(n_components)\n",
    "xtrain=pca.transform(xtrain1)\n",
    "xtrain=xtrain[:,:n_components]\n",
    "xtest=pca.transform(xtest1)\n",
    "xtest=xtest[:,:n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2009, 1) (670, 1)\n"
     ]
    }
   ],
   "source": [
    "# if LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda=LinearDiscriminantAnalysis()\n",
    "lda.fit(xtrain1,ytrain)\n",
    "xtrain=lda.transform(xtrain1)\n",
    "xtest=lda.transform(xtest1)\n",
    "print(xtrain.shape,xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3759, 4096)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if nothing\n",
    "xtrain=xtrain1\n",
    "xtest=xtest1\n",
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9817204301075269\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.9816810344827586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf=SVC(C=30.0,kernel='rbf')\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(2000, 1000, 10), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(2000,1000,10), random_state=1)\n",
    "#clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(1), random_state=1)\n",
    "clf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9779569892473118\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.978272390037096\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9708436724565757\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.9708617482951023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression(C=50)\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.941193853427896\n",
      "Test Accuracy :  0.9040043883708173\n",
      "Train F1 Score :  0.9418638621092609\n",
      "Test F1 Score :  0.9065670048051255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=7,random_state=7)\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9687328579264948\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.9692722371967655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf=BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy',max_depth=40),n_estimators=100)\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9317617866004962\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.9325153374233129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf=DecisionTreeClassifier(criterion='entropy',max_depth=40)#,max_features='sqrt')\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "h5f = h5py.File('test.h5','r')\n",
    "a = list(h5f.keys())\n",
    "## read the dataset\n",
    "full_face = []\n",
    "full_labels = []\n",
    "img_list=[h5f[i] for i in a]\n",
    "tface1 = np.zeros((len(img_list),64,64))\n",
    "for k,img in enumerate(img_list):\n",
    "    I = np.array(img)#scipy.misc.imread(os.path.join('yalefaces',img))\n",
    "    #print(type(I))\n",
    "    I = cv2.fastNlMeansDenoising(I, None, 9, 13)\n",
    "    I = cv2.GaussianBlur(I, (5,5), 0)\n",
    "    I = cv2.equalizeHist(I)\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        I,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30))\n",
    "    #print(k)\n",
    "    #print(faces)\n",
    "    try : \n",
    "        x,y,h,w = faces[0]\n",
    "        tface1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])\n",
    "    except : \n",
    "        x,y,h,w=[0,0,111,91]\n",
    "        tface1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tface1 = tface1/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs = np.genfromtxt('image_pairs.csv', dtype=None, delimiter=',', names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120, 64, 64)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clf)\n",
    "tface1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "euc=[]\n",
    "\n",
    "for i in range(3540):#(3540):\n",
    "    x1 = np.zeros((64,64))\n",
    "    x0 = np.zeros((64,64))\n",
    "    ids = test_pairs[i][0]\n",
    "    image1=test_pairs[i][1]\n",
    "    image2=test_pairs[i][2]\n",
    "    x0 = tface1[a.index(str(test_pairs[i][1])),:,:]\n",
    "    x1 = tface1[a.index(str(test_pairs[i][2])),:,:]\n",
    "    if(i%1000==0):\n",
    "        print(i)\n",
    "    face = x0-x1\n",
    "    face =euclidean_distances(face,face)# np.multiply(face,face)#abs(np.multiply(face1,face1)-np.multiply(face2,face2))#cosine_similarity(face1,face2)\n",
    "    #face=cosine_similarity(face3,face3)\n",
    "    face=face.ravel()\n",
    "    inp = np.zeros((1,64*64))\n",
    "    inp[0,:]=face\n",
    "    #inp=pca.transform(inp)\n",
    "    #inp=inp[:,:n_components]\n",
    "    euc.append(clf.predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([328])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 is similar; 0 is different\n",
    "with open('to_submit/lr_c50_nopca.csv','w') as f : \n",
    "    f.write('Id,Expected\\n')\n",
    "    for i in range(len(test_pairs)) : \n",
    "        ids = test_pairs[i][0]\n",
    "        temp = euc[i][0]\n",
    "        f.write(str(ids)+','+str(temp)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "euc = np.asarray(euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1367"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
