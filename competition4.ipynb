{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "import scipy.misc\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import hog#Terrible results; Train and test F1 score of 0 with this. \n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## read dataset1\n",
    "full_face = []\n",
    "full_labels = []\n",
    "all_images = os.listdir('yalefaces')\n",
    "for j in range(1,16):    # there are 15 different people in the dataset\n",
    "    img_list = [filename for filename in all_images if filename.startswith('subject%.2d'%j)]\n",
    "#     img_list = glob.glob('yalefaces/subject%.2d*'%j)\n",
    "    img_list=img_list[0:10]#Get only 10 faces of each category\n",
    "    face1 = np.zeros((len(img_list),64,64))\n",
    "    for k,img in enumerate(img_list):\n",
    "        I = scipy.misc.imread(os.path.join('yalefaces',img))\n",
    "        I = cv2.fastNlMeansDenoising(I, None, 9, 13)\n",
    "        I = cv2.GaussianBlur(I, (5,5), 0)\n",
    "        I = cv2.equalizeHist(I)\n",
    "\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            I,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30))\n",
    "        #fd, hog_image = hog(I, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualise=True)\n",
    "        #I = hog_image\n",
    "        #I = local_binary_pattern(I,8,3)\n",
    "        try : \n",
    "            x,y,h,w = faces[0]\n",
    "            face1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])     \n",
    "        except : \n",
    "            x,y,h,w=[0,0,479,639]\n",
    "            face1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])\n",
    "            \n",
    "        \n",
    "    labels = (j-1)*np.ones((10,))\n",
    "    full_face.append(face1)\n",
    "    full_labels.append(labels)\n",
    "#full_face = np.stack(full_face)    # contains the images of all faces\n",
    "#full_labels = np.stack(full_labels)   # contains the ID of all the faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#full_face = full_face/255 #normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#full_face.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(0,15):\\n    for j in range(50):\\n        a = np.random.randint(0,11,2)\\n        labels.append([i,i])\\n        pairs.append(a)\\n        similarity.append(1)\\n'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similar 1 dissimilar 0\n",
    "pairs = []\n",
    "labels = []\n",
    "similarity = []\n",
    "'''\n",
    "for i in range(0,15):\n",
    "    for j in range(50):\n",
    "        a = np.random.randint(0,11,2)\n",
    "        labels.append([i,i])\n",
    "        pairs.append(a)\n",
    "        similarity.append(1)\n",
    "'''       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(0,750):\\n        b = np.random.randint(0,15,2)\\n        a = np.random.randint(0,11,2)\\n        labels.append(b)\\n        pairs.append(a)\\n        if(b[0]==b[1]):\\n            similarity.append(1)\\n        else:\\n            similarity.append(0)\\n'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similar 1 dissimilar 0\n",
    "'''\n",
    "for i in range(0,750):\n",
    "        b = np.random.randint(0,15,2)\n",
    "        a = np.random.randint(0,11,2)\n",
    "        labels.append(b)\n",
    "        pairs.append(a)\n",
    "        if(b[0]==b[1]):\n",
    "            similarity.append(1)\n",
    "        else:\n",
    "            similarity.append(0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More data from att_faces\n",
    "for j in range(16,40):    # there are 40 different people in the dataset\n",
    "    img_list = []\n",
    "    for i in range(1,11):\n",
    "        img_list.append('att_faces/s'+str(j)+'/'+str(i)+'.pgm')\n",
    "#     img_list = glob.glob('yalefaces/subject%.2d*'%j)\n",
    "    face1 = np.zeros((len(img_list),64,64))\n",
    "    for k,img in enumerate(img_list):\n",
    "        I = scipy.misc.imread(img)\n",
    "        I = cv2.fastNlMeansDenoising(I, None, 9, 13)\n",
    "        I = cv2.GaussianBlur(I, (5,5), 0)\n",
    "        I = cv2.equalizeHist(I)\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            I,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30))\n",
    "        #fd, hog_image = hog(I, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualise=True)\n",
    "        #I = hog_image\n",
    "        #I = local_binary_pattern(I,8,3)\n",
    "        try : \n",
    "            x,y,h,w = faces[0]\n",
    "            face1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])     \n",
    "        except : \n",
    "            x,y,h,w=[0,0,112,92]\n",
    "            face1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])   \n",
    "        \n",
    "    labels = (j-1)*np.ones((10,))\n",
    "    full_face.append(face1)\n",
    "    full_labels.append(labels)\n",
    "full_face = np.stack(full_face)    # contains the images of all faces\n",
    "full_labels = np.stack(full_labels)   # contains the ID of all the faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_face = full_face/255 #normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_face[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#similar 1 dissimilar 0\n",
    "pairs = []\n",
    "labels = []\n",
    "similarity = []\n",
    "for i in range(0,39):\n",
    "    for j in range(40):\n",
    "        a = np.random.randint(0,10,2)\n",
    "        labels.append([i,i])\n",
    "        pairs.append(a)\n",
    "        similarity.append(1)\n",
    "#similar 1 dissimilar 0\n",
    "for i in range(0,2000):\n",
    "        b = np.random.randint(0,39,2)\n",
    "        a = np.random.randint(0,10,2)\n",
    "        labels.append(b)\n",
    "        pairs.append(a)\n",
    "        if(b[0]==b[1]):\n",
    "            similarity.append(1)\n",
    "        else:\n",
    "            similarity.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(similarity),64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.zeros((len(similarity),64*64))\n",
    "for i in range(len(similarity)):\n",
    "    a = labels[i]\n",
    "    b = pairs[i]\n",
    "    face1 = full_face[a[0],b[0],:,:]\n",
    "    face2 = full_face[a[1],b[1],:,:]\n",
    "    face = face1-face2\n",
    "    face = np.multiply(face,face)\n",
    "    #face = np.cos(face)\n",
    "    #face = cosine_similarity(face1,face2)\n",
    "    X[i,:,:]=face\n",
    "    X1[i,:]=X[i,:,:].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(X1, similarity, random_state=42, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1326\n"
     ]
    }
   ],
   "source": [
    "#Better results without PCA; so don't use this\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(whiten=True)\n",
    "pca.fit(xtrain)\n",
    "n_components = np.argmin(np.cumsum(pca.explained_variance_ratio_)<=0.99)\n",
    "print(n_components)\n",
    "xtrain=pca.transform(xtrain)\n",
    "xtrain=xtrain[:,:n_components]\n",
    "xtest=pca.transform(xtest)\n",
    "xtest=xtest[:,:n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.8865870786516854\n",
      "Test Accuracy :  0.827247191011236\n",
      "Train F1 Score :  0.8729846637829336\n",
      "Test F1 Score :  0.823021582733813\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(8,10), random_state=1)\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.884765625\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.9115442278860568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression(C=1000)\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.85546875\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.8942857142857144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=400, max_depth=16,random_state=0)#200 estimators gives good results\n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.943359375\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.9550387596899225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=200, base_estimator=RandomForestClassifier(max_depth=6))#200 n_estimators gives best results and took us to the third position on the leaderboard. \n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9564606741573034\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.9546120058565154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=200, base_estimator=RandomForestClassifier(max_depth=4))#200 n_estimators gives best results and took us to the third position on the leaderboard. \n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9676966292134831\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.9660265878877401\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=200, base_estimator=RandomForestClassifier(max_depth=6))#200 n_estimators gives best results and took us to the third position on the leaderboard. \n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9648876404494382\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.962962962962963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100, base_estimator=RandomForestClassifier(max_depth=6))#200 n_estimators gives best results and took us to the third position on the leaderboard. \n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9662921348314607\n",
      "Train F1 Score :  1.0\n",
      "Test F1 Score :  0.9658119658119657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100, base_estimator=RandomForestClassifier(max_depth=5))#200 n_estimators gives best results and took us to the third position on the leaderboard. \n",
    "clf.fit(xtrain,ytrain)\n",
    "print('Train Accuracy : ',clf.score(xtrain,ytrain))\n",
    "print('Test Accuracy : ',clf.score(xtest,ytest))\n",
    "ypred_train=clf.predict(xtrain)\n",
    "ypred_test=clf.predict(xtest)\n",
    "print('Train F1 Score : ',f1_score(y_pred=ypred_train,y_true=ytrain))\n",
    "print('Test F1 Score : ',f1_score(y_pred=ypred_test,y_true=ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "h5f = h5py.File('test.h5','r')\n",
    "a = list(h5f.keys())\n",
    "## read the dataset\n",
    "full_face = []\n",
    "full_labels = []\n",
    "img_list=[h5f[i] for i in a]\n",
    "tface1 = np.zeros((len(img_list),64,64))\n",
    "for k,img in enumerate(img_list):\n",
    "    I = np.array(img)#scipy.misc.imread(os.path.join('yalefaces',img))\n",
    "    #print(type(I))\n",
    "    I = cv2.fastNlMeansDenoising(I, None, 9, 13)\n",
    "    I = cv2.GaussianBlur(I, (5,5), 0)\n",
    "    I = cv2.equalizeHist(I)\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        I,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30))\n",
    "    #print(k)\n",
    "    #print(faces)\n",
    "    #fd, hog_image = hog(I, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualise=True)\n",
    "    #I = hog_image\n",
    "    I = local_binary_pattern(I,8,3)\n",
    "    try : \n",
    "        x,y,h,w = faces[0]\n",
    "        tface1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])\n",
    "    except : \n",
    "        x,y,h,w=[0,0,111,91]\n",
    "        tface1[k,...] = zoom(I[y:y+h,x:x+w],[64./h,64./w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 64, 64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tface1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tface1 = tface1/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pairs = np.genfromtxt('image_pairs.csv', dtype=None, delimiter=',', names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n"
     ]
    }
   ],
   "source": [
    "euc=[]\n",
    "\n",
    "for i in range(3540):#(3540):\n",
    "    x1 = np.zeros((64,64))\n",
    "    x0 = np.zeros((64,64))\n",
    "    ids = test_pairs[i][0]\n",
    "    image1=test_pairs[i][1]\n",
    "    image2=test_pairs[i][2]\n",
    "    x0 = tface1[a.index(str(test_pairs[i][1])),:,:]\n",
    "    x1 = tface1[a.index(str(test_pairs[i][2])),:,:]\n",
    "    if(i%100==0):\n",
    "        print(i)\n",
    "    face = x0-x1\n",
    "    face = np.multiply(face,face)\n",
    "    #face = np.cos(face)\n",
    "    face=face.ravel()\n",
    "    inp = np.zeros((1,64*64))\n",
    "    inp[0,:]=face\n",
    "    #inp=pca.transform(inp)\n",
    "    #inp=inp[:,:n_components]\n",
    "    euc.append(clf.predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1 is similar; 0 is different\n",
    "with open('predictions.csv','w') as f : \n",
    "    f.write('Id,Expected\\n')\n",
    "    for i in range(len(test_pairs)) : \n",
    "        ids = test_pairs[i][0]\n",
    "        temp = euc[i][0]\n",
    "        f.write(str(ids)+','+str(temp)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "euc = np.asarray(euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([267])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
